{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Prediction of Sahelian Summer Rainfall\n",
    "***\n",
    "\n",
    "#### Resources:\n",
    "* [Mardata Course](https://github.com/mardatade/Course-Python-for-Machine-Learning/blob/master/3.%20Neural%20Network.ipynb)\n",
    "* [Keras for Data Scientists](https://keras.io/getting_started/intro_to_keras_for_engineers/#data-loading-amp-preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 1. Data Loading & Preprocessing\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### a) Loading & Normalization\n",
    "\n",
    "**predictor:** contains the data used for the inputs  \n",
    "**label:** from Sahelrainfall data serves as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siod_e</th>\n",
       "      <th>siod_w</th>\n",
       "      <th>sst_med</th>\n",
       "      <th>tsa</th>\n",
       "      <th>tna</th>\n",
       "      <th>sst_mdr</th>\n",
       "      <th>sata_lnh</th>\n",
       "      <th>sata_lsh</th>\n",
       "      <th>sata_onh</th>\n",
       "      <th>sata_osh</th>\n",
       "      <th>slp_darwin</th>\n",
       "      <th>slp_tahiti</th>\n",
       "      <th>amo</th>\n",
       "      <th>nao</th>\n",
       "      <th>pdo</th>\n",
       "      <th>np</th>\n",
       "      <th>nino12</th>\n",
       "      <th>nino3</th>\n",
       "      <th>nino34</th>\n",
       "      <th>nino4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>-1.100027</td>\n",
       "      <td>-1.152764</td>\n",
       "      <td>-0.745530</td>\n",
       "      <td>-0.595366</td>\n",
       "      <td>0.388372</td>\n",
       "      <td>0.608415</td>\n",
       "      <td>-0.123443</td>\n",
       "      <td>-0.732091</td>\n",
       "      <td>-0.497808</td>\n",
       "      <td>-0.737797</td>\n",
       "      <td>0.074807</td>\n",
       "      <td>1.634819</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.917456</td>\n",
       "      <td>-0.193321</td>\n",
       "      <td>1.938388</td>\n",
       "      <td>-0.950168</td>\n",
       "      <td>-0.595561</td>\n",
       "      <td>-0.214314</td>\n",
       "      <td>-0.079270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>0.088643</td>\n",
       "      <td>0.340415</td>\n",
       "      <td>-1.507314</td>\n",
       "      <td>-0.954566</td>\n",
       "      <td>-0.346586</td>\n",
       "      <td>-0.173588</td>\n",
       "      <td>-1.289978</td>\n",
       "      <td>-0.201810</td>\n",
       "      <td>-1.175314</td>\n",
       "      <td>-0.987096</td>\n",
       "      <td>1.443896</td>\n",
       "      <td>2.682485</td>\n",
       "      <td>-0.620146</td>\n",
       "      <td>-1.172590</td>\n",
       "      <td>0.819716</td>\n",
       "      <td>-0.162154</td>\n",
       "      <td>0.991321</td>\n",
       "      <td>0.969845</td>\n",
       "      <td>1.099218</td>\n",
       "      <td>1.070532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>-0.900789</td>\n",
       "      <td>0.669332</td>\n",
       "      <td>-2.243639</td>\n",
       "      <td>-2.186294</td>\n",
       "      <td>-0.101970</td>\n",
       "      <td>0.283583</td>\n",
       "      <td>-1.333183</td>\n",
       "      <td>-1.076056</td>\n",
       "      <td>-1.415719</td>\n",
       "      <td>-1.333946</td>\n",
       "      <td>-0.071881</td>\n",
       "      <td>1.535042</td>\n",
       "      <td>-0.458290</td>\n",
       "      <td>-1.030410</td>\n",
       "      <td>-0.186187</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>-0.371251</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.524139</td>\n",
       "      <td>0.842095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>-0.949568</td>\n",
       "      <td>-1.056219</td>\n",
       "      <td>-0.079925</td>\n",
       "      <td>-1.975498</td>\n",
       "      <td>-2.214111</td>\n",
       "      <td>-1.894743</td>\n",
       "      <td>-1.135674</td>\n",
       "      <td>-1.133384</td>\n",
       "      <td>-1.863746</td>\n",
       "      <td>-1.778347</td>\n",
       "      <td>-0.903114</td>\n",
       "      <td>1.235708</td>\n",
       "      <td>-1.872482</td>\n",
       "      <td>1.447076</td>\n",
       "      <td>-0.892459</td>\n",
       "      <td>0.756497</td>\n",
       "      <td>-0.307712</td>\n",
       "      <td>-0.234313</td>\n",
       "      <td>-0.475713</td>\n",
       "      <td>-0.741738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>-0.034350</td>\n",
       "      <td>-0.632249</td>\n",
       "      <td>-0.718895</td>\n",
       "      <td>-1.684676</td>\n",
       "      <td>-1.334312</td>\n",
       "      <td>-1.014906</td>\n",
       "      <td>-1.314666</td>\n",
       "      <td>-0.595938</td>\n",
       "      <td>-1.284589</td>\n",
       "      <td>-0.954579</td>\n",
       "      <td>0.759351</td>\n",
       "      <td>-2.655622</td>\n",
       "      <td>-0.499163</td>\n",
       "      <td>-1.289888</td>\n",
       "      <td>0.545055</td>\n",
       "      <td>-0.326007</td>\n",
       "      <td>1.227830</td>\n",
       "      <td>1.497381</td>\n",
       "      <td>1.439037</td>\n",
       "      <td>1.032459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        siod_e    siod_w   sst_med       tsa       tna   sst_mdr  sata_lnh  \\\n",
       "year                                                                         \n",
       "1901 -1.100027 -1.152764 -0.745530 -0.595366  0.388372  0.608415 -0.123443   \n",
       "1902  0.088643  0.340415 -1.507314 -0.954566 -0.346586 -0.173588 -1.289978   \n",
       "1903 -0.900789  0.669332 -2.243639 -2.186294 -0.101970  0.283583 -1.333183   \n",
       "1904 -0.949568 -1.056219 -0.079925 -1.975498 -2.214111 -1.894743 -1.135674   \n",
       "1905 -0.034350 -0.632249 -0.718895 -1.684676 -1.334312 -1.014906 -1.314666   \n",
       "\n",
       "      sata_lsh  sata_onh  sata_osh  slp_darwin  slp_tahiti       amo  \\\n",
       "year                                                                   \n",
       "1901 -0.732091 -0.497808 -0.737797    0.074807    1.634819  0.923204   \n",
       "1902 -0.201810 -1.175314 -0.987096    1.443896    2.682485 -0.620146   \n",
       "1903 -1.076056 -1.415719 -1.333946   -0.071881    1.535042 -0.458290   \n",
       "1904 -1.133384 -1.863746 -1.778347   -0.903114    1.235708 -1.872482   \n",
       "1905 -0.595938 -1.284589 -0.954579    0.759351   -2.655622 -0.499163   \n",
       "\n",
       "           nao       pdo        np    nino12     nino3    nino34     nino4  \n",
       "year                                                                        \n",
       "1901  0.917456 -0.193321  1.938388 -0.950168 -0.595561 -0.214314 -0.079270  \n",
       "1902 -1.172590  0.819716 -0.162154  0.991321  0.969845  1.099218  1.070532  \n",
       "1903 -1.030410 -0.186187  0.530864 -0.371251  0.000784  0.524139  0.842095  \n",
       "1904  1.447076 -0.892459  0.756497 -0.307712 -0.234313 -0.475713 -0.741738  \n",
       "1905 -1.289888  0.545055 -0.326007  1.227830  1.497381  1.439037  1.032459  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = xr.open_dataset('data/da_pred_all.nc').to_dataframe()\n",
    "\n",
    "predictor_unit = pd.DataFrame(\n",
    "    data = StandardScaler().fit_transform(predictor), \n",
    "    columns = predictor.columns,\n",
    "    index =  predictor.index\n",
    ")\n",
    "\n",
    "\n",
    "# load validatoin data (Summer Rainfall over Sahel and scale to [cm/month]) \n",
    "labels = np.mean(np.loadtxt(\"data/da_o_sahelprecip19012017.txt\", skiprows=8,)[:,7:10] * 0.01,  axis=1)\n",
    "\n",
    "predictor_unit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### b) PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>-1.568434</td>\n",
       "      <td>-0.814406</td>\n",
       "      <td>-1.565711</td>\n",
       "      <td>-1.237071</td>\n",
       "      <td>1.472947</td>\n",
       "      <td>-0.593357</td>\n",
       "      <td>-1.660153</td>\n",
       "      <td>0.222967</td>\n",
       "      <td>0.241259</td>\n",
       "      <td>0.837099</td>\n",
       "      <td>0.098283</td>\n",
       "      <td>-0.767361</td>\n",
       "      <td>-0.099698</td>\n",
       "      <td>0.875102</td>\n",
       "      <td>-0.391004</td>\n",
       "      <td>0.067938</td>\n",
       "      <td>-0.012741</td>\n",
       "      <td>0.176348</td>\n",
       "      <td>0.188827</td>\n",
       "      <td>0.012466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>-0.521670</td>\n",
       "      <td>2.782115</td>\n",
       "      <td>-0.365347</td>\n",
       "      <td>2.152565</td>\n",
       "      <td>2.364542</td>\n",
       "      <td>0.248512</td>\n",
       "      <td>-1.855028</td>\n",
       "      <td>-0.231364</td>\n",
       "      <td>0.177858</td>\n",
       "      <td>0.788062</td>\n",
       "      <td>-0.135515</td>\n",
       "      <td>0.526785</td>\n",
       "      <td>-0.439029</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.613192</td>\n",
       "      <td>-0.173206</td>\n",
       "      <td>-0.049516</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>-0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>-2.357779</td>\n",
       "      <td>1.783520</td>\n",
       "      <td>-1.194862</td>\n",
       "      <td>1.368700</td>\n",
       "      <td>1.273662</td>\n",
       "      <td>-1.280782</td>\n",
       "      <td>-1.766921</td>\n",
       "      <td>0.441110</td>\n",
       "      <td>-0.412690</td>\n",
       "      <td>0.913848</td>\n",
       "      <td>-1.644854</td>\n",
       "      <td>0.649893</td>\n",
       "      <td>-0.240188</td>\n",
       "      <td>0.273618</td>\n",
       "      <td>0.151983</td>\n",
       "      <td>0.152255</td>\n",
       "      <td>-0.063746</td>\n",
       "      <td>0.036216</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.007985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>-5.168501</td>\n",
       "      <td>0.642722</td>\n",
       "      <td>1.054827</td>\n",
       "      <td>-0.759804</td>\n",
       "      <td>1.351015</td>\n",
       "      <td>1.020594</td>\n",
       "      <td>-0.413493</td>\n",
       "      <td>-0.695127</td>\n",
       "      <td>-0.606953</td>\n",
       "      <td>-0.289135</td>\n",
       "      <td>-0.644362</td>\n",
       "      <td>0.201273</td>\n",
       "      <td>-0.556953</td>\n",
       "      <td>0.270713</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>-0.383464</td>\n",
       "      <td>0.148037</td>\n",
       "      <td>-0.071637</td>\n",
       "      <td>0.241812</td>\n",
       "      <td>0.073306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>-1.282539</td>\n",
       "      <td>4.379097</td>\n",
       "      <td>0.640607</td>\n",
       "      <td>0.433165</td>\n",
       "      <td>-0.940971</td>\n",
       "      <td>-1.433710</td>\n",
       "      <td>1.068731</td>\n",
       "      <td>-1.191238</td>\n",
       "      <td>0.581742</td>\n",
       "      <td>-0.393126</td>\n",
       "      <td>-0.344745</td>\n",
       "      <td>-0.274467</td>\n",
       "      <td>0.226232</td>\n",
       "      <td>-0.207231</td>\n",
       "      <td>0.295327</td>\n",
       "      <td>-0.322379</td>\n",
       "      <td>0.324228</td>\n",
       "      <td>-0.052399</td>\n",
       "      <td>0.166036</td>\n",
       "      <td>0.116238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "year                                                                         \n",
       "1901 -1.568434 -0.814406 -1.565711 -1.237071  1.472947 -0.593357 -1.660153   \n",
       "1902 -0.521670  2.782115 -0.365347  2.152565  2.364542  0.248512 -1.855028   \n",
       "1903 -2.357779  1.783520 -1.194862  1.368700  1.273662 -1.280782 -1.766921   \n",
       "1904 -5.168501  0.642722  1.054827 -0.759804  1.351015  1.020594 -0.413493   \n",
       "1905 -1.282539  4.379097  0.640607  0.433165 -0.940971 -1.433710  1.068731   \n",
       "\n",
       "           PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "year                                                                         \n",
       "1901  0.222967  0.241259  0.837099  0.098283 -0.767361 -0.099698  0.875102   \n",
       "1902 -0.231364  0.177858  0.788062 -0.135515  0.526785 -0.439029  0.236945   \n",
       "1903  0.441110 -0.412690  0.913848 -1.644854  0.649893 -0.240188  0.273618   \n",
       "1904 -0.695127 -0.606953 -0.289135 -0.644362  0.201273 -0.556953  0.270713   \n",
       "1905 -1.191238  0.581742 -0.393126 -0.344745 -0.274467  0.226232 -0.207231   \n",
       "\n",
       "          PC15      PC16      PC17      PC18      PC19      PC20  \n",
       "year                                                              \n",
       "1901 -0.391004  0.067938 -0.012741  0.176348  0.188827  0.012466  \n",
       "1902  0.613192 -0.173206 -0.049516  0.003676  0.020811 -0.022700  \n",
       "1903  0.151983  0.152255 -0.063746  0.036216  0.128500  0.007985  \n",
       "1904  0.003502 -0.383464  0.148037 -0.071637  0.241812  0.073306  \n",
       "1905  0.295327 -0.322379  0.324228 -0.052399  0.166036  0.116238  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit PCA transformation\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(predictor_unit)\n",
    "\n",
    "\n",
    "# Create Create Pandas DF from PCs\n",
    "col = []\n",
    "for i in range(1, 21):\n",
    "    col.append(f'PC{i}')\n",
    "\n",
    "predictor_pc = pd.DataFrame(\n",
    "    data = principalComponents,\n",
    "    columns = col,\n",
    "    index =  predictor.index\n",
    ")\n",
    "\n",
    "# Test for unit-variance and zero mean:\n",
    "# np.std(pred_pc)\n",
    "# np.mean(pred_pc)\n",
    "# pred_pc.head()\n",
    "\n",
    "predictor_pc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 2. MODEL SETUP AND TUNING\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Clear Logs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf logs/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Hyperparameter Selection\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#####EXAMPLE SETUP FOR TESTING#####\n",
    "###################################\n",
    "\n",
    "\n",
    "#GRID SERACH HYPERPARAMETER#\n",
    "#---------------------------\n",
    "HP_INPUT_VAR_NINE = hp.HParam('input_var_nine', hp.Discrete(['PC9', 'PC14']),display_name='9th Input Variable')\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['AdamW', 'SGDW']),display_name='Optimizer')\n",
    "HP_LEARN_RATE = hp.HParam('learn_rate', hp.Discrete([0.1]),display_name='Learning Rate')\n",
    "HP_WEIGHT_DECAY = hp.HParam('weight_decay', hp.Discrete([1e-1]),display_name='Weight Decay')\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([1]),display_name='Batch Size')\n",
    "HP_EPOCHS = hp.HParam('n_epochs', hp.Discrete([3]),display_name='Epochs')\n",
    "\n",
    "\n",
    "#CROSS VALIDATION PARAMETER (NO PART OF GRID SEARCH)#\n",
    "#----------------------------------------------------\n",
    "cv_param={\n",
    "    'N_FOLDS': 2,         # number of folds -> small for Test Runs\n",
    "    'TEST_FRAC': .1    # factrion that is held out for test\n",
    "}\n",
    "\n",
    "\n",
    "#BAGGING PARAMETER (NO PART OF GRID SEARCH)#\n",
    "#-------------------------------------------\n",
    "n_baggs = 2  # number of baggs -> small for test runs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "#####FULL SETUP#####\n",
    "####################\n",
    "\n",
    "\n",
    "# #GRID SERACH HYPERPARAMETER#\n",
    "# #---------------------------\n",
    "# HP_INPUT_VAR_NINE = hp.HParam('input_var_nine', hp.Discrete(['PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16']),display_name='9th Input Variable')\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['AdamW', 'SGDW']),display_name='Optimizer')\n",
    "# HP_LEARN_RATE = hp.HParam('learn_rate', hp.Discrete([0.01, 0.1, 0.2]),display_name='Learning Rate')\n",
    "# HP_WEIGHT_DECAY = hp.HParam('weight_decay', hp.Discrete([0.001, 0.01, 0.1]),display_name='Weight Decay')\n",
    "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([1, 3, 10, 30]),display_name='Batch Size')\n",
    "# HP_EPOCHS = hp.HParam('n_epochs', hp.Discrete([30, 80, 120]),display_name='Epochs')\n",
    "\n",
    "\n",
    "# #CROSS VALIDATION PARAMETER (NO PART OF GRID SEARCH)#\n",
    "# #----------------------------------------------------\n",
    "# cv_param={\n",
    "#     'N_FOLDS': 105,      # number of folds -> sample size as in Badr\n",
    "#     'TEST_FRAC': .1    # factrion that is held out for test\n",
    "# }\n",
    "\n",
    "\n",
    "# #BAGGING PARAMETER (NO PART OF GRID SEARCH)#\n",
    "# #-------------------------------------------\n",
    "# n_baggs = 10 # number of baggs -> 10 as in Badr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Metric Selection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_TRAIN_MSE_MU= 'train_mse_mu'\n",
    "METRIC_TRAIN_MSE_SIG= 'train_,mse_sig'\n",
    "METRIC_TRAIN_CORR_MU= 'train_corr_mu'\n",
    "METRIC_TRAIN_CORR_SIG= 'train_corr_sig'\n",
    "\n",
    "METRIC_TEST_MSE_MU= 'test_mse_mu'\n",
    "METRIC_TEST_MSE_SIG= 'test_mse_sig'\n",
    "METRIC_TEST_CORR_MU= 'test_corr_mu'\n",
    "METRIC_TEST_CORR_SIG= 'test_corr_sig'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Log Experiment Confiuration to TensorBoard\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_INPUT_VAR_NINE, HP_OPTIMIZER, HP_LEARN_RATE, HP_WEIGHT_DECAY, HP_BATCH_SIZE, HP_EPOCHS],\n",
    "        metrics=[\n",
    "            hp.Metric(METRIC_TRAIN_MSE_MU, display_name='Training Sample MSE µ'),\n",
    "            hp.Metric(METRIC_TRAIN_MSE_SIG, display_name='Training Sample  MSE σ'),\n",
    "            hp.Metric(METRIC_TRAIN_CORR_MU, display_name='Training Sample Correlation µ'),\n",
    "            hp.Metric(METRIC_TRAIN_CORR_SIG, display_name='Training Sample  Correlation σ'),\n",
    "            hp.Metric(METRIC_TEST_MSE_MU, display_name='Test Sample MSE µ'),\n",
    "            hp.Metric(METRIC_TEST_MSE_SIG, display_name='Test Sample  MSE σ'),\n",
    "            hp.Metric(METRIC_TEST_CORR_MU, display_name='Test Sample Correlation µ'),\n",
    "            hp.Metric(METRIC_TEST_CORR_SIG, display_name='Test Sample  Correlation σ')\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Build Model Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(hparams):      \n",
    "    \n",
    "    \n",
    "    model = keras.Sequential([\n",
    "            layers.Dense(3, activation=\"sigmoid\", name=\"layer1\", input_shape=(9,)),\n",
    "            layers.Dense(1, activation='linear', name='output')\n",
    "        ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=getattr(tfa.optimizers, hparams[HP_OPTIMIZER])(\n",
    "            learning_rate=hparams[HP_LEARN_RATE],\n",
    "            weight_decay=hparams[HP_WEIGHT_DECAY]\n",
    "        )\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Bagging Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def Bagging(hparams, features, model, train_index, test_index):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # set emty output matrices\n",
    "    y_train_bagging = np.zeros((train_index.size, n_baggs))\n",
    "    y_test_bagging = np.zeros((test_index.size, n_baggs))    \n",
    "    \n",
    "    \n",
    "    #Train the model 'n_baggs' times and store model predictions into matrice\n",
    "    for n in range(n_baggs):\n",
    "        \n",
    "#         print ('baggin run', n)\n",
    "#         print ('PREDICTION ON TEST DATA:', y_test_bagging)\n",
    "        \n",
    "        # Bootstrap sampling from training Data with Size(Training Data)\n",
    "        train_index_bootstrap = np.random.choice(train_index, train_index.size)\n",
    "\n",
    "        #Train the model \n",
    "        model.fit(\n",
    "            features[train_index_bootstrap],\n",
    "            labels[train_index_bootstrap],\n",
    "            batch_size=hparams[HP_BATCH_SIZE],\n",
    "            epochs=hparams[HP_EPOCHS],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        #Run the model for insample data and store in one matrix:\n",
    "        y_train_bagging[:, n] = np.squeeze(model.predict(features[train_index]))\n",
    "        \n",
    "        # ... and for out of sample data        \n",
    "        y_test_bagging[:, n] = np.squeeze(model.predict(features[test_index]))\n",
    "\n",
    "    # return mean of the outputs over baggins (1st dimension)\n",
    "    return y_train_bagging.mean(1), y_test_bagging.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5cbc4f8584f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         delayed(model.fit)(\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index_bootstrap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index_bootstrap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHP_BATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "hparams = {\n",
    "                            HP_INPUT_VAR_NINE: 'PC14',\n",
    "                            HP_OPTIMIZER: 'AdamW',\n",
    "                            HP_LEARN_RATE: 0.1,\n",
    "                            HP_WEIGHT_DECAY: 0.1,\n",
    "                            HP_BATCH_SIZE: 2,\n",
    "                            HP_EPOCHS: 2,                \n",
    "                        }\n",
    "\n",
    "features = predictor_pc.loc[:,['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', hparams[HP_INPUT_VAR_NINE]]].to_numpy()\n",
    "\n",
    "for train_index, test_index in ShuffleSplit(n_splits=2, test_size=cv_param['TEST_FRAC']).split(features):\n",
    "    model = BuildModel(hparams)\n",
    "    \n",
    "    for n in range(n_baggs):\n",
    "        \n",
    "#         print ('baggin run', n)\n",
    "#         print ('PREDICTION ON TEST DATA:', y_test_bagging)\n",
    "        \n",
    "        # Bootstrap sampling from training Data with Size(Training Data)\n",
    "        train_index_bootstrap = np.random.choice(train_index, train_index.size)\n",
    "\n",
    "        #Train the model \n",
    "        delayed(model.fit)(\n",
    "            features[train_index_bootstrap],\n",
    "            labels[train_index_bootstrap],\n",
    "            batch_size=hparams[HP_BATCH_SIZE],\n",
    "            epochs=hparams[HP_EPOCHS],\n",
    "            verbose=1\n",
    "        )\n",
    "        print (1)\n",
    "        print(train_index_bootstrap)\n",
    "    print (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "53/53 [==============================] - 0s 623us/step - loss: 4.8789\n",
      "Epoch 2/2\n",
      "53/53 [==============================] - 0s 710us/step - loss: 3.7693\n",
      "Epoch 1/2\n",
      "53/53 [==============================] - 0s 566us/step - loss: 3.5018\n",
      "Epoch 2/2\n",
      "53/53 [==============================] - 0s 822us/step - loss: 3.3732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.11739838, 1.23990098, 0.48289761, 1.0686627 , 1.36163718,\n",
       "        0.89569843, 1.37432522, 1.10477647, 1.17239708, 1.3715536 ,\n",
       "        1.22822797, 1.01563278, 1.15959752, 1.28290015, 0.62352872,\n",
       "        1.16564068, 1.18425566, 1.13892633, 0.67885071, 0.49271929,\n",
       "        1.12655601, 1.20708767, 1.20702472, 1.07973254, 0.66773185,\n",
       "        1.35773224, 0.61714071, 0.68854991, 0.87080178, 1.42444152,\n",
       "        0.85274279, 1.10196218, 0.92388058, 0.65844119, 0.90855756,\n",
       "        1.29325613, 0.8403244 , 0.65514585, 1.03674126, 0.48486894,\n",
       "        1.43158782, 1.33575529, 1.35264063, 0.74879757, 1.2925784 ,\n",
       "        1.01509029, 0.9297657 , 0.89216855, 1.1768671 , 1.29426891,\n",
       "        0.88363096, 1.0449194 , 1.34580421, 0.75758216, 0.81056172,\n",
       "        0.77526391, 1.03279221, 0.54241636, 1.3684212 , 0.96079496,\n",
       "        0.86120987, 1.15987235, 0.43783817, 1.20041078, 1.12119615,\n",
       "        0.56498587, 0.89609101, 1.38589126, 1.06642717, 0.93917245,\n",
       "        0.89819843, 1.40392476, 0.84337202, 1.10323948, 1.30388674,\n",
       "        1.19928899, 1.14285886, 0.73098388, 0.82200176, 1.11451277,\n",
       "        0.87116292, 0.63887274, 1.24979013, 1.04110324, 0.83391541,\n",
       "        0.71079256, 0.81588501, 1.12440369, 1.23839489, 0.81306857,\n",
       "        0.88530964, 0.96837455, 1.21512723, 1.39803678, 1.24020222,\n",
       "        1.40365249, 0.7312707 , 1.06936184, 0.77737305, 0.72328186,\n",
       "        1.2257506 , 1.19811481, 1.03894132, 0.84888709, 1.12155476]),\n",
       " array([0.73319975, 0.81485638, 0.70895386, 1.16827112, 1.42912132,\n",
       "        0.91388005, 0.94055504, 0.7655507 , 0.8167243 , 1.14933866,\n",
       "        1.19855985, 0.83959925]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Cross Validation Training & Error Calculation Funktion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(hparams, cv_param, predictor_pc, labels):\n",
    "        \n",
    "    \n",
    "    train_mse = np.empty(cv_param['N_FOLDS'])\n",
    "    train_corr = np.empty(cv_param['N_FOLDS'])\n",
    "    \n",
    "    test_mse = np.empty(cv_param['N_FOLDS'])\n",
    "    test_corr = np.empty(cv_param['N_FOLDS'])\n",
    "    \n",
    "    #choose Inputs\n",
    "    features = predictor_pc.loc[:,['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', hparams[HP_INPUT_VAR_NINE]]].to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Cross Validation#\n",
    "    ##################\n",
    "    \n",
    "    cv_fold = 0\n",
    "    \n",
    "    for train_index, test_index in ShuffleSplit(n_splits=cv_param['N_FOLDS'], test_size=cv_param['TEST_FRAC']).split(features):\n",
    "        \n",
    "#         print(cv_fold)\n",
    "#         print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        \n",
    "    \n",
    "        # Build the model according to definition:\n",
    "        model = BuildModel(hparams)\n",
    "        \n",
    "        # Train and predict using Bagging    \n",
    "        y_train, y_test = Bagging(hparams, features, model, train_index, test_index)\n",
    "        \n",
    "        \n",
    "        #Compute error metrics for in sample data\n",
    "        train_err=  y_train - labels[train_index]\n",
    "        train_mse[cv_fold] = np.mean(train_err**2)\n",
    "        train_corr[cv_fold] = st.pearsonr(y_train, labels[train_index])[0]\n",
    "        \n",
    "        # ... and for out of sample data\n",
    "        test_err=  y_test - labels[test_index]\n",
    "        test_mse[cv_fold] = np.mean(test_err**2)\n",
    "        test_corr[cv_fold] = st.pearsonr(y_test, labels[test_index])[0]\n",
    "        \n",
    "        \n",
    "#         print ( \"BAGGING OUT Test\", y_test)\n",
    "        cv_fold += 1\n",
    "    \n",
    "    #######################################################################################################\n",
    "    \n",
    "    \n",
    "    #Error Moments#\n",
    "    ###############\n",
    "    \n",
    "    eval_metrics = {\n",
    "        'train_mse_mu': np.mean(train_mse),\n",
    "        'train_mse_sig': np.std(train_mse),\n",
    "        'train_corr_mu': np.mean(train_corr),\n",
    "        'train_corr_sig': np.std(train_corr),            \n",
    "        'test_mse_mu': np.mean(test_mse),\n",
    "        'test_mse_sig': np.std(test_mse),\n",
    "        'test_corr_mu': np.mean(test_corr),\n",
    "        'test_corr_sig': np.std(test_corr),\n",
    "    }\n",
    "    \n",
    "#     print(eval_metrics)\n",
    "    \n",
    "    return eval_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model Run and Log Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "                            HP_INPUT_VAR_NINE: 'PC14',\n",
    "                            HP_OPTIMIZER: 'AdamW',\n",
    "                            HP_LEARN_RATE: 0.1,\n",
    "                            HP_WEIGHT_DECAY: 0.1,\n",
    "                            HP_BATCH_SIZE: 2,\n",
    "                            HP_EPOCHS: 2,                \n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 ms, sys: 0 ns, total: 1.03 ms\n",
      "Wall time: 922 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eval_metrics = TrainModel(hparams, cv_param, predictor_pc, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 ms, sys: 0 ns, total: 1.63 ms\n",
      "Wall time: 1.59 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for n in range(2):\n",
    "     eval_metrics = TrainModel(hparams, cv_param, predictor_pc, labels)\n",
    "    \n",
    "    \n",
    "# eval_metrics.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RunModel(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        \n",
    "        eval_metrics = delayed(TrainModel)(hparams, cv_param, predictor_pc, labels)\n",
    "        eval_metrics.a()\n",
    "        tf.summary.scalar(METRIC_TRAIN_MSE_MU,   eval_metrics['train_mse_mu'],   step=1)\n",
    "        tf.summary.scalar(METRIC_TRAIN_MSE_SIG,  eval_metrics['train_mse_sig'],  step=1)\n",
    "        tf.summary.scalar(METRIC_TRAIN_CORR_MU,  eval_metrics['train_corr_mu'],  step=1)\n",
    "        tf.summary.scalar(METRIC_TRAIN_CORR_SIG, eval_metrics['train_corr_sig'], step=1)\n",
    "        tf.summary.scalar(METRIC_TEST_MSE_MU,    eval_metrics['test_mse_mu'],    step=1)\n",
    "        tf.summary.scalar(METRIC_TEST_MSE_SIG,   eval_metrics['test_mse_sig'],   step=1)\n",
    "        tf.summary.scalar(METRIC_TEST_CORR_MU,   eval_metrics['test_corr_mu'],   step=1)\n",
    "        tf.summary.scalar(METRIC_TEST_CORR_SIG,  eval_metrics['test_corr_sig'],  step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Grid Search\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "TypeError: Delayed objects of unspecified length have no len()\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.8/site-packages/dask/delayed.py\", line 568, in __len__\n    raise TypeError(\"Delayed objects of unspecified length have no len()\")\n\nTypeError: Delayed objects of unspecified length have no len()\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-5228a0c3904e>\u001b[0m in \u001b[0;36mRunModel\u001b[0;34m(run_dir, hparams)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0meval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor_pc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0meval_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC_TRAIN_MSE_MU\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0meval_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_mse_mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC_TRAIN_MSE_SIG\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0meval_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_mse_sig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC_TRAIN_CORR_MU\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0meval_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_corr_mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorboard/plugins/scalar/summary_v2.py\u001b[0m in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msummary_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scalar_summary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         return tf.summary.write(\n\u001b[1;32m     65\u001b[0m             \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/check_ops.py\u001b[0m in \u001b[0;36massert_scalar_v2\u001b[0;34m(tensor, message, name)\u001b[0m\n\u001b[1;32m   2179\u001b[0m       \u001b[0munknown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m   \"\"\"\n\u001b[0;32m-> 2181\u001b[0;31m   \u001b[0massert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/check_ops.py\u001b[0m in \u001b[0;36massert_scalar\u001b[0;34m(tensor, name, message)\u001b[0m\n\u001b[1;32m   2205\u001b[0m   \"\"\"\n\u001b[1;32m   2206\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'assert_scalar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2207\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2208\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: TypeError: Delayed objects of unspecified length have no len()\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.8/site-packages/dask/delayed.py\", line 568, in __len__\n    raise TypeError(\"Delayed objects of unspecified length have no len()\")\n\nTypeError: Delayed objects of unspecified length have no len()\n\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "session_num = 0        \n",
    "\n",
    "for input_var_nine in HP_INPUT_VAR_NINE.domain.values:\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        for learn_rate in HP_LEARN_RATE.domain.values:\n",
    "            for weight_decay in HP_WEIGHT_DECAY.domain.values:\n",
    "                for batch_size in HP_BATCH_SIZE.domain.values:\n",
    "                    for n_epochs in HP_EPOCHS.domain.values:\n",
    "\n",
    "\n",
    "                        hparams = {\n",
    "                            HP_INPUT_VAR_NINE: input_var_nine,\n",
    "                            HP_OPTIMIZER: optimizer,\n",
    "                            HP_LEARN_RATE: learn_rate,\n",
    "                            HP_WEIGHT_DECAY: weight_decay,\n",
    "                            HP_BATCH_SIZE: batch_size,\n",
    "                            HP_EPOCHS: n_epochs,                \n",
    "                        }\n",
    "\n",
    "                        run_name = f\"run-{session_num}\"\n",
    "#                         print(f'--- Starting trial: {run_name}')\n",
    "#                         print({h.name: hparams[h] for h in hparams})\n",
    "                        RunModel('logs/hparam_tuning/' + run_name, hparams)\n",
    "                        session_num += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
