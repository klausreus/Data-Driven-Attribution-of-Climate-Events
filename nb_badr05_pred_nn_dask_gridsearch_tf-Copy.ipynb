{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Prediction of Sahelian Summer Rainfall\n",
    "***\n",
    "\n",
    "#### Resources:\n",
    "* [Mardata Course](https://github.com/mardatade/Course-Python-for-Machine-Learning/blob/master/3.%20Neural%20Network.ipynb)\n",
    "* [Keras for Data Scientists](https://keras.io/getting_started/intro_to_keras_for_engineers/#data-loading-amp-preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "%load_ext tensorboard\n",
    "\n",
    "import dask\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 1. Data Loading & Preprocessing\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### a) Loading & Normalization\n",
    "\n",
    "**predictor:** contains the data used for the inputs  \n",
    "**label:** from Sahelrainfall data serves as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siod_e</th>\n",
       "      <th>siod_w</th>\n",
       "      <th>sst_med</th>\n",
       "      <th>tsa</th>\n",
       "      <th>tna</th>\n",
       "      <th>sst_mdr</th>\n",
       "      <th>sata_lnh</th>\n",
       "      <th>sata_lsh</th>\n",
       "      <th>sata_onh</th>\n",
       "      <th>sata_osh</th>\n",
       "      <th>slp_darwin</th>\n",
       "      <th>slp_tahiti</th>\n",
       "      <th>amo</th>\n",
       "      <th>nao</th>\n",
       "      <th>pdo</th>\n",
       "      <th>np</th>\n",
       "      <th>nino12</th>\n",
       "      <th>nino3</th>\n",
       "      <th>nino34</th>\n",
       "      <th>nino4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>-1.100027</td>\n",
       "      <td>-1.152764</td>\n",
       "      <td>-0.745530</td>\n",
       "      <td>-0.595366</td>\n",
       "      <td>0.388372</td>\n",
       "      <td>0.608415</td>\n",
       "      <td>-0.123443</td>\n",
       "      <td>-0.732091</td>\n",
       "      <td>-0.497808</td>\n",
       "      <td>-0.737797</td>\n",
       "      <td>0.074807</td>\n",
       "      <td>1.634819</td>\n",
       "      <td>0.923204</td>\n",
       "      <td>0.917456</td>\n",
       "      <td>-0.193321</td>\n",
       "      <td>1.938388</td>\n",
       "      <td>-0.950168</td>\n",
       "      <td>-0.595561</td>\n",
       "      <td>-0.214314</td>\n",
       "      <td>-0.079270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>0.088643</td>\n",
       "      <td>0.340415</td>\n",
       "      <td>-1.507314</td>\n",
       "      <td>-0.954566</td>\n",
       "      <td>-0.346586</td>\n",
       "      <td>-0.173588</td>\n",
       "      <td>-1.289978</td>\n",
       "      <td>-0.201810</td>\n",
       "      <td>-1.175314</td>\n",
       "      <td>-0.987096</td>\n",
       "      <td>1.443896</td>\n",
       "      <td>2.682485</td>\n",
       "      <td>-0.620146</td>\n",
       "      <td>-1.172590</td>\n",
       "      <td>0.819716</td>\n",
       "      <td>-0.162154</td>\n",
       "      <td>0.991321</td>\n",
       "      <td>0.969845</td>\n",
       "      <td>1.099218</td>\n",
       "      <td>1.070532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>-0.900789</td>\n",
       "      <td>0.669332</td>\n",
       "      <td>-2.243639</td>\n",
       "      <td>-2.186294</td>\n",
       "      <td>-0.101970</td>\n",
       "      <td>0.283583</td>\n",
       "      <td>-1.333183</td>\n",
       "      <td>-1.076056</td>\n",
       "      <td>-1.415719</td>\n",
       "      <td>-1.333946</td>\n",
       "      <td>-0.071881</td>\n",
       "      <td>1.535042</td>\n",
       "      <td>-0.458290</td>\n",
       "      <td>-1.030410</td>\n",
       "      <td>-0.186187</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>-0.371251</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.524139</td>\n",
       "      <td>0.842095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>-0.949568</td>\n",
       "      <td>-1.056219</td>\n",
       "      <td>-0.079925</td>\n",
       "      <td>-1.975498</td>\n",
       "      <td>-2.214111</td>\n",
       "      <td>-1.894743</td>\n",
       "      <td>-1.135674</td>\n",
       "      <td>-1.133384</td>\n",
       "      <td>-1.863746</td>\n",
       "      <td>-1.778347</td>\n",
       "      <td>-0.903114</td>\n",
       "      <td>1.235708</td>\n",
       "      <td>-1.872482</td>\n",
       "      <td>1.447076</td>\n",
       "      <td>-0.892459</td>\n",
       "      <td>0.756497</td>\n",
       "      <td>-0.307712</td>\n",
       "      <td>-0.234313</td>\n",
       "      <td>-0.475713</td>\n",
       "      <td>-0.741738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>-0.034350</td>\n",
       "      <td>-0.632249</td>\n",
       "      <td>-0.718895</td>\n",
       "      <td>-1.684676</td>\n",
       "      <td>-1.334312</td>\n",
       "      <td>-1.014906</td>\n",
       "      <td>-1.314666</td>\n",
       "      <td>-0.595938</td>\n",
       "      <td>-1.284589</td>\n",
       "      <td>-0.954579</td>\n",
       "      <td>0.759351</td>\n",
       "      <td>-2.655622</td>\n",
       "      <td>-0.499163</td>\n",
       "      <td>-1.289888</td>\n",
       "      <td>0.545055</td>\n",
       "      <td>-0.326007</td>\n",
       "      <td>1.227830</td>\n",
       "      <td>1.497381</td>\n",
       "      <td>1.439037</td>\n",
       "      <td>1.032459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        siod_e    siod_w   sst_med       tsa       tna   sst_mdr  sata_lnh  \\\n",
       "year                                                                         \n",
       "1901 -1.100027 -1.152764 -0.745530 -0.595366  0.388372  0.608415 -0.123443   \n",
       "1902  0.088643  0.340415 -1.507314 -0.954566 -0.346586 -0.173588 -1.289978   \n",
       "1903 -0.900789  0.669332 -2.243639 -2.186294 -0.101970  0.283583 -1.333183   \n",
       "1904 -0.949568 -1.056219 -0.079925 -1.975498 -2.214111 -1.894743 -1.135674   \n",
       "1905 -0.034350 -0.632249 -0.718895 -1.684676 -1.334312 -1.014906 -1.314666   \n",
       "\n",
       "      sata_lsh  sata_onh  sata_osh  slp_darwin  slp_tahiti       amo  \\\n",
       "year                                                                   \n",
       "1901 -0.732091 -0.497808 -0.737797    0.074807    1.634819  0.923204   \n",
       "1902 -0.201810 -1.175314 -0.987096    1.443896    2.682485 -0.620146   \n",
       "1903 -1.076056 -1.415719 -1.333946   -0.071881    1.535042 -0.458290   \n",
       "1904 -1.133384 -1.863746 -1.778347   -0.903114    1.235708 -1.872482   \n",
       "1905 -0.595938 -1.284589 -0.954579    0.759351   -2.655622 -0.499163   \n",
       "\n",
       "           nao       pdo        np    nino12     nino3    nino34     nino4  \n",
       "year                                                                        \n",
       "1901  0.917456 -0.193321  1.938388 -0.950168 -0.595561 -0.214314 -0.079270  \n",
       "1902 -1.172590  0.819716 -0.162154  0.991321  0.969845  1.099218  1.070532  \n",
       "1903 -1.030410 -0.186187  0.530864 -0.371251  0.000784  0.524139  0.842095  \n",
       "1904  1.447076 -0.892459  0.756497 -0.307712 -0.234313 -0.475713 -0.741738  \n",
       "1905 -1.289888  0.545055 -0.326007  1.227830  1.497381  1.439037  1.032459  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = xr.open_dataset('data/da_pred_all.nc').to_dataframe()\n",
    "\n",
    "predictor_unit = pd.DataFrame(\n",
    "    data = StandardScaler().fit_transform(predictor), \n",
    "    columns = predictor.columns,\n",
    "    index =  predictor.index\n",
    ")\n",
    "\n",
    "\n",
    "# load validatoin data (Summer Rainfall over Sahel and scale to [cm/month]) \n",
    "labels = np.mean(np.loadtxt(\"data/da_o_sahelprecip19012017.txt\", skiprows=8,)[:,7:10] * 0.01,  axis=1)\n",
    "\n",
    "predictor_unit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### b) PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>-1.568434</td>\n",
       "      <td>-0.814406</td>\n",
       "      <td>-1.565711</td>\n",
       "      <td>-1.237071</td>\n",
       "      <td>1.472947</td>\n",
       "      <td>-0.593357</td>\n",
       "      <td>-1.660153</td>\n",
       "      <td>0.222967</td>\n",
       "      <td>0.241259</td>\n",
       "      <td>0.837099</td>\n",
       "      <td>0.098283</td>\n",
       "      <td>-0.767361</td>\n",
       "      <td>-0.099698</td>\n",
       "      <td>0.875102</td>\n",
       "      <td>-0.391004</td>\n",
       "      <td>0.067938</td>\n",
       "      <td>-0.012741</td>\n",
       "      <td>0.176348</td>\n",
       "      <td>0.188827</td>\n",
       "      <td>0.012466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>-0.521670</td>\n",
       "      <td>2.782115</td>\n",
       "      <td>-0.365347</td>\n",
       "      <td>2.152565</td>\n",
       "      <td>2.364542</td>\n",
       "      <td>0.248512</td>\n",
       "      <td>-1.855028</td>\n",
       "      <td>-0.231364</td>\n",
       "      <td>0.177858</td>\n",
       "      <td>0.788062</td>\n",
       "      <td>-0.135515</td>\n",
       "      <td>0.526785</td>\n",
       "      <td>-0.439029</td>\n",
       "      <td>0.236945</td>\n",
       "      <td>0.613192</td>\n",
       "      <td>-0.173206</td>\n",
       "      <td>-0.049516</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.020811</td>\n",
       "      <td>-0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>-2.357779</td>\n",
       "      <td>1.783520</td>\n",
       "      <td>-1.194862</td>\n",
       "      <td>1.368700</td>\n",
       "      <td>1.273662</td>\n",
       "      <td>-1.280782</td>\n",
       "      <td>-1.766921</td>\n",
       "      <td>0.441110</td>\n",
       "      <td>-0.412690</td>\n",
       "      <td>0.913848</td>\n",
       "      <td>-1.644854</td>\n",
       "      <td>0.649893</td>\n",
       "      <td>-0.240188</td>\n",
       "      <td>0.273618</td>\n",
       "      <td>0.151983</td>\n",
       "      <td>0.152255</td>\n",
       "      <td>-0.063746</td>\n",
       "      <td>0.036216</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.007985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>-5.168501</td>\n",
       "      <td>0.642722</td>\n",
       "      <td>1.054827</td>\n",
       "      <td>-0.759804</td>\n",
       "      <td>1.351015</td>\n",
       "      <td>1.020594</td>\n",
       "      <td>-0.413493</td>\n",
       "      <td>-0.695127</td>\n",
       "      <td>-0.606953</td>\n",
       "      <td>-0.289135</td>\n",
       "      <td>-0.644362</td>\n",
       "      <td>0.201273</td>\n",
       "      <td>-0.556953</td>\n",
       "      <td>0.270713</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>-0.383464</td>\n",
       "      <td>0.148037</td>\n",
       "      <td>-0.071637</td>\n",
       "      <td>0.241812</td>\n",
       "      <td>0.073306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>-1.282539</td>\n",
       "      <td>4.379097</td>\n",
       "      <td>0.640607</td>\n",
       "      <td>0.433165</td>\n",
       "      <td>-0.940971</td>\n",
       "      <td>-1.433710</td>\n",
       "      <td>1.068731</td>\n",
       "      <td>-1.191238</td>\n",
       "      <td>0.581742</td>\n",
       "      <td>-0.393126</td>\n",
       "      <td>-0.344745</td>\n",
       "      <td>-0.274467</td>\n",
       "      <td>0.226232</td>\n",
       "      <td>-0.207231</td>\n",
       "      <td>0.295327</td>\n",
       "      <td>-0.322379</td>\n",
       "      <td>0.324228</td>\n",
       "      <td>-0.052399</td>\n",
       "      <td>0.166036</td>\n",
       "      <td>0.116238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "year                                                                         \n",
       "1901 -1.568434 -0.814406 -1.565711 -1.237071  1.472947 -0.593357 -1.660153   \n",
       "1902 -0.521670  2.782115 -0.365347  2.152565  2.364542  0.248512 -1.855028   \n",
       "1903 -2.357779  1.783520 -1.194862  1.368700  1.273662 -1.280782 -1.766921   \n",
       "1904 -5.168501  0.642722  1.054827 -0.759804  1.351015  1.020594 -0.413493   \n",
       "1905 -1.282539  4.379097  0.640607  0.433165 -0.940971 -1.433710  1.068731   \n",
       "\n",
       "           PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "year                                                                         \n",
       "1901  0.222967  0.241259  0.837099  0.098283 -0.767361 -0.099698  0.875102   \n",
       "1902 -0.231364  0.177858  0.788062 -0.135515  0.526785 -0.439029  0.236945   \n",
       "1903  0.441110 -0.412690  0.913848 -1.644854  0.649893 -0.240188  0.273618   \n",
       "1904 -0.695127 -0.606953 -0.289135 -0.644362  0.201273 -0.556953  0.270713   \n",
       "1905 -1.191238  0.581742 -0.393126 -0.344745 -0.274467  0.226232 -0.207231   \n",
       "\n",
       "          PC15      PC16      PC17      PC18      PC19      PC20  \n",
       "year                                                              \n",
       "1901 -0.391004  0.067938 -0.012741  0.176348  0.188827  0.012466  \n",
       "1902  0.613192 -0.173206 -0.049516  0.003676  0.020811 -0.022700  \n",
       "1903  0.151983  0.152255 -0.063746  0.036216  0.128500  0.007985  \n",
       "1904  0.003502 -0.383464  0.148037 -0.071637  0.241812  0.073306  \n",
       "1905  0.295327 -0.322379  0.324228 -0.052399  0.166036  0.116238  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit PCA transformation\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(predictor_unit)\n",
    "\n",
    "\n",
    "# Create Create Pandas DF from PCs\n",
    "col = []\n",
    "for i in range(1, 21):\n",
    "    col.append(f'PC{i}')\n",
    "\n",
    "predictor_pc = pd.DataFrame(\n",
    "    data = principalComponents,\n",
    "    columns = col,\n",
    "    index =  predictor.index\n",
    ")\n",
    "\n",
    "# Test for unit-variance and zero mean:\n",
    "# np.std(pred_pc)\n",
    "# np.mean(pred_pc)\n",
    "# pred_pc.head()\n",
    "\n",
    "predictor_pc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## 2. MODEL SETUP AND TUNING\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Clear Logs\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf logs/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Hyperparameter Selection\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#####EXAMPLE SETUP FOR TESTING#####\n",
    "###################################\n",
    "\n",
    "\n",
    "#GRID SERACH HYPERPARAMETER#\n",
    "#---------------------------\n",
    "HP_INPUT_VAR_NINE = hp.HParam('input_var_nine', hp.Discrete(['PC9']),display_name='9th Input Variable')\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['AdamW']),display_name='Optimizer')\n",
    "HP_LEARN_RATE = hp.HParam('learn_rate', hp.Discrete([0.1]),display_name='Learning Rate')\n",
    "HP_WEIGHT_DECAY = hp.HParam('weight_decay', hp.Discrete([1e-1]),display_name='Weight Decay')\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([1]),display_name='Batch Size')\n",
    "HP_EPOCHS = hp.HParam('n_epochs', hp.Discrete([10, 20]),display_name='Epochs')\n",
    "\n",
    "\n",
    "#CROSS VALIDATION PARAMETER (NO PART OF GRID SEARCH)#\n",
    "#----------------------------------------------------\n",
    "cv_param={\n",
    "    'N_FOLDS': 2,         # number of folds -> small for Test Runs\n",
    "    'TEST_FRAC': .1    # factrion that is held out for test\n",
    "}\n",
    "\n",
    "\n",
    "#BAGGING PARAMETER (NO PART OF GRID SEARCH)#\n",
    "#-------------------------------------------\n",
    "n_baggs = 5  # number of baggs -> small for test runs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "#####FULL SETUP#####\n",
    "####################\n",
    "\n",
    "\n",
    "# #GRID SERACH HYPERPARAMETER#\n",
    "# #---------------------------\n",
    "# HP_INPUT_VAR_NINE = hp.HParam('input_var_nine', hp.Discrete(['PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16']),display_name='9th Input Variable')\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['AdamW', 'SGDW']),display_name='Optimizer')\n",
    "# HP_LEARN_RATE = hp.HParam('learn_rate', hp.Discrete([0.01, 0.1, 0.2]),display_name='Learning Rate')\n",
    "# HP_WEIGHT_DECAY = hp.HParam('weight_decay', hp.Discrete([0.001, 0.01, 0.1]),display_name='Weight Decay')\n",
    "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([1, 3, 10, 30]),display_name='Batch Size')\n",
    "# HP_EPOCHS = hp.HParam('n_epochs', hp.Discrete([30, 80, 120]),display_name='Epochs')\n",
    "\n",
    "\n",
    "# #CROSS VALIDATION PARAMETER (NO PART OF GRID SEARCH)#\n",
    "# #----------------------------------------------------\n",
    "# cv_param={\n",
    "#     'N_FOLDS': 105,      # number of folds -> sample size as in Badr\n",
    "#     'TEST_FRAC': .1    # factrion that is held out for test\n",
    "# }\n",
    "\n",
    "\n",
    "# #BAGGING PARAMETER (NO PART OF GRID SEARCH)#\n",
    "# #-------------------------------------------\n",
    "# n_baggs = 10 # number of baggs -> 10 as in Badr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Metric Selection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_TRAIN_MSE_MU= 'train_mse_mu'\n",
    "METRIC_TRAIN_MSE_SIG= 'train_,mse_sig'\n",
    "METRIC_TRAIN_CORR_MU= 'train_corr_mu'\n",
    "METRIC_TRAIN_CORR_SIG= 'train_corr_sig'\n",
    "\n",
    "METRIC_TEST_MSE_MU= 'test_mse_mu'\n",
    "METRIC_TEST_MSE_SIG= 'test_mse_sig'\n",
    "METRIC_TEST_CORR_MU= 'test_corr_mu'\n",
    "METRIC_TEST_CORR_SIG= 'test_corr_sig'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Log Experiment Confiuration to TensorBoard\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_INPUT_VAR_NINE, HP_OPTIMIZER, HP_LEARN_RATE, HP_WEIGHT_DECAY, HP_BATCH_SIZE, HP_EPOCHS],\n",
    "        metrics=[\n",
    "            hp.Metric(METRIC_TRAIN_MSE_MU, display_name='Training Sample MSE µ'),\n",
    "#             hp.Metric(METRIC_TRAIN_MSE_SIG, display_name='Training Sample  MSE σ'),\n",
    "#             hp.Metric(METRIC_TRAIN_CORR_MU, display_name='Training Sample Correlation µ'),\n",
    "#             hp.Metric(METRIC_TRAIN_CORR_SIG, display_name='Training Sample  Correlation σ'),\n",
    "            hp.Metric(METRIC_TEST_MSE_MU, display_name='Test Sample MSE µ'),\n",
    "#             hp.Metric(METRIC_TEST_MSE_SIG, display_name='Test Sample  MSE σ'),\n",
    "#             hp.Metric(METRIC_TEST_CORR_MU, display_name='Test Sample Correlation µ'),\n",
    "#             hp.Metric(METRIC_TEST_CORR_SIG, display_name='Test Sample  Correlation σ')\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Build Model Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(hparams):      \n",
    "    \n",
    "    \n",
    "    model = keras.Sequential([\n",
    "            layers.Dense(3, activation=\"sigmoid\", name=\"layer1\", input_shape=(9,)),\n",
    "            layers.Dense(1, activation='linear', name='output')\n",
    "        ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=getattr(tfa.optimizers, hparams[HP_OPTIMIZER])(\n",
    "            learning_rate=hparams[HP_LEARN_RATE],\n",
    "            weight_decay=hparams[HP_WEIGHT_DECAY]\n",
    "        )\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Bagging Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bagging(hparams, features, model, train_index, test_index):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # set emty output matrices\n",
    "    y_train_bagging = np.zeros((train_index.size, n_baggs))\n",
    "    y_test_bagging = np.zeros((test_index.size, n_baggs))    \n",
    "    \n",
    "    \n",
    "    #Train the model 'n_baggs' times and store model predictions into matrice\n",
    "    for n in range(n_baggs):\n",
    "        \n",
    "#         print ('baggin run', n)\n",
    "#         print ('PREDICTION ON TEST DATA:', y_test_bagging)\n",
    "        \n",
    "        # Bootstrap sampling from training Data with Size(Training Data)\n",
    "        train_index_bootstrap = np.random.choice(train_index, train_index.size)\n",
    "\n",
    "        #Train the model \n",
    "        model.fit(\n",
    "            features[train_index_bootstrap],\n",
    "            labels[train_index_bootstrap],\n",
    "            batch_size=hparams[HP_BATCH_SIZE],\n",
    "            epochs=hparams[HP_EPOCHS],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        #Run the model for insample data and store in one matrix:\n",
    "        y_train_bagging[:, n] = np.squeeze(model.predict(features[train_index]))\n",
    "        \n",
    "        # ... and for out of sample data        \n",
    "        y_test_bagging[:, n] = np.squeeze(model.predict(features[test_index]))\n",
    "\n",
    "    # return mean of the outputs over baggins (1st dimension)\n",
    "    return y_train_bagging.mean(1), y_test_bagging.mean(1)\n",
    "#     return y_test_bagging.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Cross Validation Training & Error Calculation Funktion\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(hparams, cv_param, predictor_pc, labels):\n",
    "        \n",
    "    \n",
    "#     train_mse = np.empty(cv_param['N_FOLDS'])\n",
    "#     train_corr = np.empty(cv_param['N_FOLDS'])\n",
    "    \n",
    "#     test_mse = np.empty(cv_param['N_FOLDS'])\n",
    "#     test_corr = np.empty(cv_param['N_FOLDS'])\n",
    "    train_mse = []\n",
    "    test_mse = []\n",
    "    \n",
    "    \n",
    "    #choose Inputs\n",
    "    features = predictor_pc.loc[:,['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', hparams[HP_INPUT_VAR_NINE]]].to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Cross Validation#\n",
    "    ##################\n",
    "    \n",
    "    cv_fold = 0\n",
    "    \n",
    "    for train_index, test_index in ShuffleSplit(n_splits=cv_param['N_FOLDS'], test_size=cv_param['TEST_FRAC']).split(features):\n",
    "        \n",
    "#         print(cv_fold)\n",
    "#         print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        \n",
    "    \n",
    "        # Build the model according to definition:\n",
    "        model = BuildModel(hparams)\n",
    "        \n",
    "        # Train and predict using Bagging    \n",
    "        y_train_test = delayed(Bagging)(hparams, features, model, train_index, test_index)\n",
    "        \n",
    "        \n",
    "        #Compute error metrics for in sample data\n",
    "        train_err = y_train_test[0] - labels[train_index]\n",
    "        train_mse.append(np.mean(train_err**2))\n",
    "        \n",
    "        # ... and for out of sample data\n",
    "        test_err =  y_train_test[1] - labels[test_index]\n",
    "        test_mse.append(np.mean(test_err**2))\n",
    "        \n",
    "        \n",
    "#         print ( \"BAGGING OUT Test\", y_test)\n",
    "        cv_fold += 1\n",
    "    \n",
    "    #######################################################################################################\n",
    "    result_test = delayed(np.mean)(test_mse)\n",
    "    result_train= delayed(np.mean)(train_mse)\n",
    "    \n",
    "    train_mse_mu, test_mse_mu = dask.compute(result_test, result_train)\n",
    "    #Error Moments#\n",
    "    ###############\n",
    "    \n",
    "    eval_metrics = {\n",
    "        'train_mse_mu': train_mse_mu,\n",
    "#         'train_mse_sig': np.std(train_mse),\n",
    "#         'train_corr_mu': np.mean(train_corr),\n",
    "#         'train_corr_sig': np.std(train_corr),            \n",
    "        'test_mse_mu': test_mse_mu,\n",
    "#         'test_mse_sig': np.std(test_mse),\n",
    "#         'test_corr_mu': np.mean(test_corr),\n",
    "#         'test_corr_sig': np.std(test_corr),\n",
    "    }\n",
    "    \n",
    "#     print(eval_metrics)\n",
    "    \n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Model Run and Log Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunModel(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        \n",
    "        eval_metrics = TrainModel(hparams, cv_param, predictor_pc, labels)\n",
    "        tf.summary.scalar(METRIC_TRAIN_MSE_MU,   eval_metrics['train_mse_mu'],   step=1)\n",
    "#         tf.summary.scalar(METRIC_TRAIN_MSE_SIG,  eval_metrics['train_mse_sig'],  step=1)\n",
    "#         tf.summary.scalar(METRIC_TRAIN_CORR_MU,  eval_metrics['train_corr_mu'],  step=1)\n",
    "#         tf.summary.scalar(METRIC_TRAIN_CORR_SIG, eval_metrics['train_corr_sig'], step=1)\n",
    "        tf.summary.scalar(METRIC_TEST_MSE_MU,    eval_metrics['test_mse_mu'],    step=1)\n",
    "#         tf.summary.scalar(METRIC_TEST_MSE_SIG,   eval_metrics['test_mse_sig'],   step=1)\n",
    "#         tf.summary.scalar(METRIC_TEST_CORR_MU,   eval_metrics['test_corr_mu'],   step=1)\n",
    "#         tf.summary.scalar(METRIC_TEST_CORR_SIG,  eval_metrics['test_corr_sig'],  step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Grid Search\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'input_var_nine': 'PC9', 'optimizer': 'AdamW', 'learn_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 1, 'n_epochs': 10}\n",
      "--- Starting trial: run-1\n",
      "{'input_var_nine': 'PC9', 'optimizer': 'AdamW', 'learn_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 1, 'n_epochs': 20}\n",
      "CPU times: user 23.2 s, sys: 2.91 s, total: 26.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "session_num = 0        \n",
    "\n",
    "for input_var_nine in HP_INPUT_VAR_NINE.domain.values:\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "        for learn_rate in HP_LEARN_RATE.domain.values:\n",
    "            for weight_decay in HP_WEIGHT_DECAY.domain.values:\n",
    "                for batch_size in HP_BATCH_SIZE.domain.values:\n",
    "                    for n_epochs in HP_EPOCHS.domain.values:\n",
    "\n",
    "\n",
    "                        hparams = {\n",
    "                            HP_INPUT_VAR_NINE: input_var_nine,\n",
    "                            HP_OPTIMIZER: optimizer,\n",
    "                            HP_LEARN_RATE: learn_rate,\n",
    "                            HP_WEIGHT_DECAY: weight_decay,\n",
    "                            HP_BATCH_SIZE: batch_size,\n",
    "                            HP_EPOCHS: n_epochs,                \n",
    "                        }\n",
    "\n",
    "                        run_name = f\"run-{session_num}\"\n",
    "                        print(f'--- Starting trial: {run_name}')\n",
    "                        print({h.name: hparams[h] for h in hparams})\n",
    "                        RunModel('logs/hparam_tuning/' + run_name, hparams)\n",
    "                        session_num += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
